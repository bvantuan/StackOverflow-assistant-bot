{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StarSpace.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnT_l3D9Zmgf",
        "outputId": "492036e5-565f-48e4-807a-4040fd24199a"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsXPjjcnZqPl"
      },
      "source": [
        "DATA_FOLDER = \"/content/drive/My Drive/StackOverflow Assistant Chatbot\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZvi8jxsZxhz"
      },
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from gensim.models import KeyedVectors\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fclUisLDa3J1"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVvwz4TSwp7r"
      },
      "source": [
        "# Word embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK6e1CPvwrT7"
      },
      "source": [
        "[Pre-trained word vectors](https://code.google.com/archive/p/word2vec/) from Google which were trained on a part of Google News dataset (about 100 billion words)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msa7TaMsZ1xL"
      },
      "source": [
        "# Load word embeddings, a mapping between keys and vectors of 300 dimensions\n",
        "oWordEmbeddings = KeyedVectors.load_word2vec_format(f'{DATA_FOLDER}/GoogleNews-vectors-negative300.bin.gz', binary=True, limit=500000) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cUeYm6iaGWz",
        "outputId": "d5660c7f-18ea-4d1e-980c-196d309878ec"
      },
      "source": [
        "type(oWordEmbeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gensim.models.keyedvectors.Word2VecKeyedVectors"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntKrTihPfCfD",
        "outputId": "1342b096-8a68-447a-c344-e494d972b23a"
      },
      "source": [
        "# Example of most similar word\n",
        "clMostSimilarWord = oWordEmbeddings.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "clMostSimilarWord"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118192911148071),\n",
              " ('monarch', 0.6189674139022827),\n",
              " ('princess', 0.5902431011199951),\n",
              " ('crown_prince', 0.5499460697174072),\n",
              " ('prince', 0.5377321243286133),\n",
              " ('kings', 0.5236844420433044),\n",
              " ('queens', 0.518113374710083),\n",
              " ('sultan', 0.5098593235015869),\n",
              " ('monarchy', 0.5087411999702454),\n",
              " ('royal_palace', 0.5087165832519531)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQSFeSENfKf7"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: QuestionEmbedding\n",
        "    \n",
        "    Objective: Calculate question embedding\n",
        "    \n",
        "    Summary algorithmic description: a mean of all word embedding in the question\n",
        "    \n",
        "    Input parameters: sQuestion : question to embed\n",
        "                      oWordEmbeddings : dictionnary where the key is a word and a value is it's embedding\n",
        "                      iDim : size of the question embedding\n",
        "    \n",
        "    Return : question embedding\n",
        "    \n",
        "    Date : 28/11/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def QuestionEmbedding(sQuestion, oWordEmbeddings, iDim=300):\n",
        "    #  question embedding is initialized with filled zeros\n",
        "    caResult = np.zeros(iDim)\n",
        "    # Number of embedded words\n",
        "    iCount = 0\n",
        "    # Loop over all words of this question\n",
        "    for sWord in sQuestion.split():\n",
        "        # If word is embedded\n",
        "        if sWord in oWordEmbeddings:\n",
        "            # Add this embedding to question embedding\n",
        "            caResult += oWordEmbeddings[sWord]\n",
        "            # Number of embedded words inscrease\n",
        "            iCount += 1\n",
        "    # Return a mean of all word embedding in the question\n",
        "    return caResult / iCount if iCount != 0 else caResult"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWQA_Qy_QFcw"
      },
      "source": [
        "### Hits@K\n",
        "\n",
        "The first simple metric will be a number of correct hits for some *K*:\n",
        "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [dup_i \\in topK(q_i)]$$\n",
        "\n",
        "where $q_i$ is the i-th query, $dup_i$ is its duplicate, $topK(q_i)$ is the top K elements of the ranked sentences provided by our model and the operation $[dup_i \\in topK(q_i)]$ equals 1 if the condition is true and 0 otherwise (more details about this operation could be found [here](https://en.wikipedia.org/wiki/Iverson_bracket)).\n",
        "\n",
        "\n",
        "### DCG@K\n",
        "The second one is a simplified [DCG metric](https://en.wikipedia.org/wiki/Discounted_cumulative_gain):\n",
        "\n",
        "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le K] $$\n",
        "\n",
        "where $rank_{dup_i}$ is a position of the duplicate in the sorted list of the nearest sentences for the query $q_i$. According to this metric, the model gets a higher reward for a higher position of the correct answer. If the answer does not appear in topK at all, the reward is zero. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Oz4k-U1iErL"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: HitsCount\n",
        "    \n",
        "    Objective: metric of correct sentence is the top K elements of the ranked sentences\n",
        "    \n",
        "    Summary algorithmic description: 1 if the first duplicate is lower than K\n",
        "    \n",
        "    Input parameters: clDuplicateRank : list of duplicates ranks; one rank per question; \n",
        "                                        e.g. [2, 3] means that the first duplicate has the rank 2, the second one has the rank 3.\n",
        "                      iK : number of top-ranked elements (k in Hits@k metric)\n",
        "    \n",
        "    Return : Hits@k value for current ranking\n",
        "    \n",
        "    Date : 04/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def HitsCount(clDuplicateRank, iK):\n",
        "    return sum(iRank <= iK for iRank in clDuplicateRank) / len(clDuplicateRank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p-inDKpio_C"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: DCGScore\n",
        "    \n",
        "    Objective: Calculate the DCG score\n",
        "    \n",
        "    Summary algorithmic description: log2(1 + rank) if the first duplicate those rank is lower than K\n",
        "    \n",
        "    Input parameters: clDuplicateRank : list of duplicates ranks; one rank per question; \n",
        "                                        e.g. [2, 3] means that the first duplicate has the rank 2, the second one has the rank 3.\n",
        "                      iK : number of top-ranked elements (k in Hits@k metric)\n",
        "    \n",
        "    Return : DCG@k value for current ranking\n",
        "    \n",
        "    Date : 04/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def DCGScore(dup_ranks, k):\n",
        "    return sum(1 / (np.log2(1 + rank)) for rank in dup_ranks if rank <= k) / len(dup_ranks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0vYuv8fisgy"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: ReadCorpus\n",
        "    \n",
        "    Objective: Read data corpus\n",
        "    \n",
        "    Summary algorithmic description: Read all lines in the file\n",
        "                                     Add every line to the list\n",
        "    \n",
        "    Input parameters: sFilePath : a file path\n",
        "    \n",
        "    Return : list of [question, similar question, negative example 1, negative example 2, ...] \n",
        "    \n",
        "    Date : 04/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def ReadCorpus(sFilePath):\n",
        "    # list of [question, similar question, negative example 1, negative example 2, ...] \n",
        "    clData = []\n",
        "    # Loop over all lines of file\n",
        "    for sLine in open(sFilePath, encoding='utf-8'):\n",
        "        # Add [question, similar question, negative example 1, negative example 2, ...] to the list\n",
        "        clData.append(sLine.strip().split('\\t'))\n",
        "    # Return list of [question, similar question, negative example 1, negative example 2, ...] \n",
        "    return clData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n82G_YxNk7rE"
      },
      "source": [
        "# Read validation corpus\n",
        "clValData = ReadCorpus(f'{DATA_FOLDER}/validation.tsv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aG0-Tuvk91y"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: RankCandidates\n",
        "    \n",
        "    Objective: Rank candidates in a sorted list of pairs\n",
        "    \n",
        "    Summary algorithmic description: Compute cosine similarity between question and its candidates.\n",
        "                                     Sort the list depend on its cosine similarities\n",
        "    \n",
        "    Input parameters: sQuestion : a question\n",
        "                      clCandidates : a list of candidate questions which we want to rank\n",
        "                      oWordEmbeddings : words embedding\n",
        "                      iDim : dimension of the current embeddings\n",
        "    \n",
        "    Return : a sorted list of pairs (initial position in candidates list, candidate); the first is the best\n",
        "    \n",
        "    Date : 04/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def RankCandidates(sQuestion, clCandidates, oWordEmbeddings, iDim=300):\n",
        "    # question embedding\n",
        "    caQuestionEmbedding = QuestionEmbedding(sQuestion, oWordEmbeddings, iDim)[np.newaxis, :]\n",
        "    # embeddings of candidate questions \n",
        "    caQuestionCandidateEmbeddings = np.array([QuestionEmbedding(sCandidateQuestion, oWordEmbeddings, iDim) for sCandidateQuestion in clCandidates])\n",
        "    # Compute cosine similarity between question and its candidates.\n",
        "    caCosineSimilarity = cosine_similarity(caQuestionEmbedding, caQuestionCandidateEmbeddings)[0]\n",
        "    # the indices that would sort the similarities\n",
        "    caSortedIndex = np.argsort(caCosineSimilarity)[::-1]\n",
        "    # a sorted list of pairs (initial position in candidates list, candidate); the first is the best\n",
        "    return [(iIndex, clCandidates[iIndex]) for iIndex in caSortedIndex]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JCO5keQlORS"
      },
      "source": [
        "# list of ranks of smilar questions\n",
        "clSimilarQuestionRank = []\n",
        "# Loop over all questions in validattion set\n",
        "for clData in clValData:\n",
        "    # question and its duplicated candidates \n",
        "    sQuestion, *clCandidates = clData\n",
        "    # a sorted list of pairs (initial position in candidates list, candidate); the first is the best\n",
        "    clCandidateRank = RankCandidates(sQuestion, clCandidates, oWordEmbeddings)\n",
        "    # Add rank of smilar question to the list\n",
        "    clSimilarQuestionRank.append([ctPair[0] for ctPair in clCandidateRank].index(0) + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUwELSKSnmbC",
        "outputId": "590870b3-a448-413c-cceb-484b27b71bbd"
      },
      "source": [
        "# Different values of k\n",
        "for iK in [1, 5, 10, 100, 500, 1000]:\n",
        "    # DCG score and hits count\n",
        "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (iK, DCGScore(clSimilarQuestionRank, iK), iK, HitsCount(clSimilarQuestionRank, iK)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DCG@   1: 0.209 | Hits@   1: 0.209\n",
            "DCG@   5: 0.263 | Hits@   5: 0.311\n",
            "DCG@  10: 0.279 | Hits@  10: 0.360\n",
            "DCG@ 100: 0.316 | Hits@ 100: 0.548\n",
            "DCG@ 500: 0.349 | Hits@ 500: 0.807\n",
            "DCG@1000: 0.369 | Hits@1000: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu7xG7wzoJoa"
      },
      "source": [
        "# special characters replaced by space\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "# Remove characters that are not 0-9, a-z, ' ', #, +, _\n",
        "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "# stop words\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm1n6eylaafw"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: CleanRawText\n",
        "    \n",
        "    Objective: Clean a raw text\n",
        "    \n",
        "    Summary algorithmic description: All characters in text are lower case\n",
        "                                     Remove characters that are not 0-9, a-z, ' ', #, +, _\n",
        "                                     Remove stop words\n",
        "    \n",
        "    Input parameters: sText : a text\n",
        "    \n",
        "    Return : the preprocessed text\n",
        "    \n",
        "    Date : 04/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def CleanRawText(sText):\n",
        "    # all characters in sText are lower case \n",
        "    sText = sText.lower()\n",
        "    # special characters replaced by space\n",
        "    sText = REPLACE_BY_SPACE_RE.sub(' ', sText)\n",
        "    # Remove characters that are not 0-9, a-z, ' ', #, +, _\n",
        "    sText = GOOD_SYMBOLS_RE.sub('', sText)\n",
        "    # Remove stop words\n",
        "    sText = ' '.join([sWord for sWord in sText.split() if sWord and sWord not in STOPWORDS])\n",
        "    # Return preprocessed text\n",
        "    return sText.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3OJxLMZcuEe"
      },
      "source": [
        "# cleaned validation data\n",
        "clCleanedValData = []\n",
        "# Loop over all datas in validation data\n",
        "for clData in clValData:\n",
        "    # Clean every question in data\n",
        "    clCleanedValData.append([CleanRawText(sQuestion) for sQuestion in clData])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaDv6mXceZjw"
      },
      "source": [
        "# list of ranks of smilar cleaned questions\n",
        "clSimilarCleanedQuestionRank = []\n",
        "# Loop over all questions in cleaned validattion set\n",
        "for clData in clCleanedValData:\n",
        "    # question and its duplicated candidates \n",
        "    sQuestion, *clCandidates = clData\n",
        "    # a sorted list of pairs (initial position in candidates list, candidate); the first is the best\n",
        "    clCandidateRank = RankCandidates(sQuestion, clCandidates, oWordEmbeddings)\n",
        "    # Add rank of smilar question to the list\n",
        "    clSimilarCleanedQuestionRank.append([ctPair[0] for ctPair in clCandidateRank].index(0) + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8t_T9zQesW3",
        "outputId": "660d1507-1c81-408f-cc30-b9c76797a051"
      },
      "source": [
        "# Different values of k\n",
        "for iK in [1, 5, 10, 100, 500, 1000]:\n",
        "    # DCG score and hits count\n",
        "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (iK, DCGScore(clSimilarCleanedQuestionRank, iK), iK, HitsCount(clSimilarCleanedQuestionRank, iK)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DCG@   1: 0.305 | Hits@   1: 0.305\n",
            "DCG@   5: 0.375 | Hits@   5: 0.438\n",
            "DCG@  10: 0.392 | Hits@  10: 0.489\n",
            "DCG@ 100: 0.425 | Hits@ 100: 0.656\n",
            "DCG@ 500: 0.447 | Hits@ 500: 0.830\n",
            "DCG@1000: 0.465 | Hits@1000: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqK4nIlyw7uC"
      },
      "source": [
        "## Representations using StarSpace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftdl44yqg5uv"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: CleanTextsInFile\n",
        "    \n",
        "    Objective: Clean texts in a file\n",
        "    \n",
        "    Summary algorithmic description: Open cleaned file\n",
        "                                     Write cleaned texts from file in the cleaned file\n",
        "\n",
        "    Input parameters: sFilePath : a file path to clean texts\n",
        "                      sCleanedFilePath : a cleaned file from the source file\n",
        "    \n",
        "    Return : None\n",
        "    \n",
        "    Date : 04/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def CleanTextsInFile(sFilePath, sCleanedFilePath):\n",
        "    # Open cleaned file\n",
        "    oCleanedFilePath = open(sCleanedFilePath, 'w')\n",
        "    # Loop over all datas in file\n",
        "    for sData in open(sFilePath, encoding='utf8'):\n",
        "        # Read every text in data\n",
        "        clData = sData.strip().split('\\t')\n",
        "        # Clean every text in data\n",
        "        clCleanedText = [CleanRawText(sText) for sText in clData]\n",
        "        # Write cleaned texts in the cleaned file\n",
        "        print(*clCleanedText, sep='\\t', file=oCleanedFilePath)\n",
        "    # Close cleaned file\n",
        "    oCleanedFilePath.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ8uz5xziIIp"
      },
      "source": [
        "CleanTextsInFile(f'{DATA_FOLDER}/train.tsv', f'{DATA_FOLDER}/cleaned_train.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7k5mYzEUMos",
        "outputId": "a0e5a024-c66b-4374-e18b-8775ac460261"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/Starspace.git\n",
        "%cd Starspace\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Starspace' already exists and is not an empty directory.\n",
            "/content/Starspace\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops -g -c src/utils/normalize.cpp\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/dict.cpp\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops -g -c src/utils/args.cpp\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/proj.cpp\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/parser.cpp -o parser.o\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/data.cpp -o data.o\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/model.cpp\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/starspace.cpp\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/doc_parser.cpp -o doc_parser.o\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/doc_data.cpp -o doc_data.o\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/utils/utils.cpp -o utils.o\n",
            "g++ -pthread -std=gnu++11 -O3 -funroll-loops normalize.o dict.o args.o proj.o parser.o data.o model.o starspace.o doc_parser.o doc_data.o utils.o -I/usr/local/bin/boost_1_63_0/ -g src/main.cpp -o starspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMoy9ikbjzhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880eb8bb-d828-455a-e290-c79537a73e3f"
      },
      "source": [
        "######### TRAINING HAPPENING HERE #############\n",
        "! ./starspace train -trainFile '{DATA_FOLDER}/cleaned_train.tsv' -model StarSpace_embeddings \\\n",
        "-trainMode 3 \\\n",
        "-adagrad true \\\n",
        "-ngrams 1 \\\n",
        "-epoch 5 \\\n",
        "-dim 100 \\\n",
        "-similarity cosine \\\n",
        "-minCount 2 \\\n",
        "-verbose true \\\n",
        "-fileFormat labelDoc \\\n",
        "-negSearchLimit 10 \\\n",
        "-lr 0.05"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arguments: \n",
            "lr: 0.05\n",
            "dim: 100\n",
            "epoch: 5\n",
            "maxTrainTime: 8640000\n",
            "validationPatience: 10\n",
            "saveEveryEpoch: 0\n",
            "loss: hinge\n",
            "margin: 0.05\n",
            "similarity: cosine\n",
            "maxNegSamples: 10\n",
            "negSearchLimit: 10\n",
            "batchSize: 5\n",
            "thread: 10\n",
            "minCount: 2\n",
            "minCountLabel: 1\n",
            "label: __label__\n",
            "label: __label__\n",
            "ngrams: 1\n",
            "bucket: 2000000\n",
            "adagrad: 1\n",
            "trainMode: 3\n",
            "fileFormat: labelDoc\n",
            "normalizeText: 0\n",
            "dropoutLHS: 0\n",
            "dropoutRHS: 0\n",
            "useWeight: 0\n",
            "weightSep: :\n",
            "Start to initialize starspace model.\n",
            "Build dict from input file : /content/drive/My Drive/StackOverflow Assistant Chatbot/cleaned_train.tsv\n",
            "Read 12M words\n",
            "Number of words in dictionary:  95058\n",
            "Number of labels in dictionary: 0\n",
            "Loading data from file : /content/drive/My Drive/StackOverflow Assistant Chatbot/cleaned_train.tsv\n",
            "Total number of examples loaded : 999740\n",
            "Initialized model weights. Model size :\n",
            "matrix : 95058 100\n",
            "Training epoch 0: 0.05 0.01\n",
            "Epoch: 100.0%  lr: 0.040000  loss: 0.043943  eta: 0h13m  tot: 0h3m16s  (20.0%)\n",
            " ---+++                Epoch    0 Train error : 0.04383477 +++--- ☃\n",
            "Training epoch 1: 0.04 0.01\n",
            "Epoch: 100.0%  lr: 0.030000  loss: 0.013133  eta: 0h9m  tot: 0h6m18s  (40.0%)\n",
            " ---+++                Epoch    1 Train error : 0.01320854 +++--- ☃\n",
            "Training epoch 2: 0.03 0.01\n",
            "Epoch: 100.0%  lr: 0.020000  loss: 0.009459  eta: 0h5m  tot: 0h9m16s  (60.0%)\n",
            " ---+++                Epoch    2 Train error : 0.00947345 +++--- ☃\n",
            "Training epoch 3: 0.02 0.01\n",
            "Epoch: 100.0%  lr: 0.010000  loss: 0.007846  eta: 0h2m  tot: 0h12m15s  (80.0%)\n",
            " ---+++                Epoch    3 Train error : 0.00772147 +++--- ☃\n",
            "Training epoch 4: 0.01 0.01\n",
            "Epoch: 100.0%  lr: 0.000000  loss: 0.006763  eta: <1min   tot: 0h15m12s  (100.0%)\n",
            " ---+++                Epoch    4 Train error : 0.00684006 +++--- ☃\n",
            "Saving model to file : StarSpace_embeddings\n",
            "Saving model in tsv format : StarSpace_embeddings.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWMz1rXlZQMN"
      },
      "source": [
        "# a mapping between keys and vectors of 100 dimensions\n",
        "cdStarspaceEmbedding = {}\n",
        "# Open file starspace embedding\n",
        "with open('/content/Starspace/StarSpace_embeddings.tsv', encoding='utf-8') as f:  \n",
        "    # Read every line in file\n",
        "    for line in f.readlines():\n",
        "        # Separate key and vector\n",
        "        clLine = line.strip().split('\\t')\n",
        "        # Add key and vector embedding into the dictionnary\n",
        "        cdStarspaceEmbedding[clLine[0]] = np.array(clLine[1:], dtype=np.float32)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzhdyx7-ZmZW"
      },
      "source": [
        "# list of ranks of smilar cleaned questions by using Starspace embedding\n",
        "clStarspaceSimilarCleanedQuestionRank = []\n",
        "# Loop over all questions in cleaned validation set\n",
        "for clData in clCleanedValData:\n",
        "    # question and its duplicated candidates \n",
        "    sQuestion, *clCandidates = clData\n",
        "    # a sorted list of pairs (initial position in candidates list, candidate); the first is the best\n",
        "    clCandidateRank = RankCandidates(sQuestion, clCandidates, cdStarspaceEmbedding, 100)\n",
        "    # Add rank of similar question to the list\n",
        "    clStarspaceSimilarCleanedQuestionRank.append([ctPair[0] for ctPair in clCandidateRank].index(0) + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xveCDHyabX0t",
        "outputId": "06108479-3f0a-48ab-8e5a-ab2b1a43cd75"
      },
      "source": [
        "# Different values of k\n",
        "for iK in [1, 5, 10, 100, 500, 1000]:\n",
        "    # DCG score and hits count\n",
        "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (iK, DCGScore(clStarspaceSimilarCleanedQuestionRank, iK), iK, HitsCount(clStarspaceSimilarCleanedQuestionRank, iK)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DCG@   1: 0.520 | Hits@   1: 0.520\n",
            "DCG@   5: 0.615 | Hits@   5: 0.698\n",
            "DCG@  10: 0.634 | Hits@  10: 0.756\n",
            "DCG@ 100: 0.665 | Hits@ 100: 0.904\n",
            "DCG@ 500: 0.675 | Hits@ 500: 0.979\n",
            "DCG@1000: 0.677 | Hits@1000: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga2uew8pcevn"
      },
      "source": [
        "!cp '/content/Starspace/StarSpace_embeddings.tsv' \"/content/drive/My Drive/StackOverflow Assistant Chatbot\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnjKSCnVclHf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}