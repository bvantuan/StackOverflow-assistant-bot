{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyxxWp6D7HI0",
        "outputId": "4dcb439d-afba-458b-e763-13db11ed1cbb"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVZCiBE-7Uxy",
        "outputId": "5a5dfa50-2b77-4c2c-94b7-85e9e6ccbd07"
      },
      "source": [
        "!pip install chatterbot\n",
        "!pip install chatterbot_corpus"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chatterbot\n",
            "  Downloading ChatterBot-1.0.8-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 20 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 30 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from chatterbot) (2.8.2)\n",
            "Collecting sqlalchemy<1.4,>=1.3\n",
            "  Downloading SQLAlchemy-1.3.24-cp37-cp37m-manylinux2010_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 11.7 MB/s \n",
            "\u001b[?25hCollecting mathparse<0.2,>=0.1\n",
            "  Downloading mathparse-0.1.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from chatterbot) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<2.9,>=2.8->chatterbot) (1.15.0)\n",
            "Installing collected packages: sqlalchemy, mathparse, chatterbot\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.27\n",
            "    Uninstalling SQLAlchemy-1.4.27:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.27\n",
            "Successfully installed chatterbot-1.0.8 mathparse-0.1.2 sqlalchemy-1.3.24\n",
            "Collecting chatterbot_corpus\n",
            "  Downloading chatterbot_corpus-1.2.0-py2.py3-none-any.whl (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML<4.0,>=3.12 in /usr/local/lib/python3.7/dist-packages (from chatterbot_corpus) (3.13)\n",
            "Installing collected packages: chatterbot-corpus\n",
            "Successfully installed chatterbot-corpus-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk3vtg1z7K7H"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
        "\n",
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ChatterBotCorpusTrainer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZWpMF2S7TLW",
        "outputId": "a389b2fe-a040-40f3-f619-2c7f0c7eb6e7"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtrKoYAe79Q1"
      },
      "source": [
        "DATA_FOLDER = \"/content/drive/My Drive/StackOverflow Assistant Chatbot\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8GtUCRO7jPp"
      },
      "source": [
        "# Intent recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPkEShPh-Emu"
      },
      "source": [
        "We will do a binary classification on TF-IDF representations of texts. Labels will be either dialogue for general questions or stackoverflow for programming-related questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrNOtX_A8L_f"
      },
      "source": [
        "# Load TF-IDF features and tags\n",
        "caTrainFeatureTFIDF, caTestFeatureTFIDF, clTrainTag, clTestTag = pickle.load(open(f'{DATA_FOLDER}/tfidf_features.pkl', 'rb')) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86yo_VV29j0g",
        "outputId": "68da1d54-b6a2-474d-8cd5-dbe67a0a34d2"
      },
      "source": [
        "# Logistic Regression classifier\n",
        "oIntentRecognizer = LogisticRegression(penalty='l2', C=10, random_state=0, solver='liblinear')\n",
        "# Fit the model according to the given training data\n",
        "oIntentRecognizer.fit(caTrainFeatureTFIDF, clTrainTag)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10, random_state=0, solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvFLbKod-Hz2",
        "outputId": "1be4a269-0a8a-43f0-fc8d-6cb6eb6e926a"
      },
      "source": [
        "# Predict class labels for test set\n",
        "caTestTagPrediction = oIntentRecognizer.predict(caTestFeatureTFIDF)\n",
        "# Accuracy classification score\n",
        "fTestAccuracy = accuracy_score(clTestTag, caTestTagPrediction)\n",
        "print('Test accuracy = {}'.format(fTestAccuracy))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 0.991575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alp6yl7Z-KJL"
      },
      "source": [
        "# Dump the classifier\n",
        "pickle.dump(oIntentRecognizer, open(f'{DATA_FOLDER}/intent_recognizer.pkl', 'wb'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AeeQspk-TVm"
      },
      "source": [
        "# Programming language classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyvfdWCh-VF-"
      },
      "source": [
        "We will train one more classifier for the programming-related questions. It will predict exactly one tag (=programming language) and will be also based on Logistic Regression with TF-IDF features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9e7lGSy-NAW"
      },
      "source": [
        "# Load cleaned sample data\n",
        "dfDialogue, dfStackOverflow = pickle.load(open(f'{DATA_FOLDER}/cleaned_sample_data.pkl', 'rb')) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6f6pWFc-gYX"
      },
      "source": [
        "# StackOverflow titles\n",
        "caStackOverflowTitle = dfStackOverflow['title'].values\n",
        "# StackOverflow tags\n",
        "caStackOverflowTag = dfStackOverflow['tag'].values"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TkSKQe6-lT2",
        "outputId": "f81ffb0f-b6c7-43cd-9add-b3f47f83ddaa"
      },
      "source": [
        "# Split StackOverflow datas into random train and test subsets\n",
        "caTrainStackOverflowTitle, caTestStackOverflowTitle, caTrainStackOverflowTag, caTestStackOverflowTag = train_test_split(caStackOverflowTitle, caStackOverflowTag, test_size=0.2, random_state=0)\n",
        "print('Train size = {}, test size = {}'.format(len(caTrainStackOverflowTitle), len(caTestStackOverflowTitle)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size = 160000, test size = 40000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhE5wnEL-n5o"
      },
      "source": [
        "# reuse the TF-IDF vectorizer\n",
        "oTFIDFVectorizer = pickle.load(open(f'{DATA_FOLDER}/tfidf_vectorizer.pkl', 'rb'))\n",
        "# Transform documents to document-term matrix\n",
        "caTrainTFIDFFeature, caTestTFIDFFeature = oTFIDFVectorizer.transform(caTrainStackOverflowTitle), oTFIDFVectorizer.transform(caTestStackOverflowTitle)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NXMtiIP-qQ2",
        "outputId": "de25e5ee-68fc-4f30-d8f5-4d6771ee1ea7"
      },
      "source": [
        "# tag classifier using OneVsRestClassifier wrapper over LogisticRegression\n",
        "oTagClassifier = OneVsRestClassifier(LogisticRegression(penalty='l2', C=5, random_state=0, solver='liblinear'))\n",
        "# Fit the model\n",
        "oTagClassifier.fit(caTrainTFIDFFeature, caTrainStackOverflowTag)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(C=5, random_state=0,\n",
              "                                                 solver='liblinear'))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qjDCfh_-sl5",
        "outputId": "67ed91b3-f69f-4a55-b5cb-4d1c698fd52e"
      },
      "source": [
        "# Predict class labels for test set\n",
        "caTestTagPrediction = oTagClassifier.predict(caTestTFIDFFeature)\n",
        "# Accuracy classification score\n",
        "fTestAccuracy = accuracy_score(caTestStackOverflowTag, caTestTagPrediction)\n",
        "print('Test accuracy = {}'.format(fTestAccuracy))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 0.800725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smNa5rZu-w16"
      },
      "source": [
        "# Dump tag classifier\n",
        "pickle.dump(oTagClassifier, open(f'{DATA_FOLDER}/tag_classifier.pkl', 'wb'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBxglRLc_Dn-"
      },
      "source": [
        "# Dialogue Manager"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQr9KhW8q2_Z"
      },
      "source": [
        "# special characters replaced by space\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "# Remove characters that are not 0-9, a-z, ' ', #, +, _\n",
        "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "# stop words\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pdlbFfPnD5j"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: CleanRawText\n",
        "    \n",
        "    Objective: Clean a raw text\n",
        "    \n",
        "    Summary algorithmic description: All characters in text are lower case\n",
        "                                     Remove characters that are not 0-9, a-z, ' ', #, +, _\n",
        "                                     Remove stop words\n",
        "    \n",
        "    Input parameters: sText : a text\n",
        "    \n",
        "    Return : the preprocessed text\n",
        "    \n",
        "    Date : 04/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def CleanRawText(sText):\n",
        "    # all characters in sText are lower case \n",
        "    sText = sText.lower()\n",
        "    # special characters replaced by space\n",
        "    sText = REPLACE_BY_SPACE_RE.sub(' ', sText)\n",
        "    # Remove characters that are not 0-9, a-z, ' ', #, +, _\n",
        "    sText = GOOD_SYMBOLS_RE.sub('', sText)\n",
        "    # Remove stop words\n",
        "    sText = ' '.join([sWord for sWord in sText.split() if sWord and sWord not in STOPWORDS])\n",
        "    # Return preprocessed text\n",
        "    return sText.strip()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUwmRszQrDlT"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: QuestionEmbedding\n",
        "    \n",
        "    Objective: Calculate question embedding\n",
        "    \n",
        "    Summary algorithmic description: a mean of all word embedding in the question\n",
        "    \n",
        "    Input parameters: sQuestion : question to embed\n",
        "                      oWordEmbeddings : dictionnary where the key is a word and a value is it's embedding\n",
        "                      iDim : size of the question embedding\n",
        "    \n",
        "    Return : question embedding\n",
        "    \n",
        "    Date : 28/11/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def QuestionEmbedding(sQuestion, oWordEmbeddings, iDim=300):\n",
        "    #  question embedding is initialized with filled zeros\n",
        "    caResult = np.zeros(iDim)\n",
        "    # Number of embedded words\n",
        "    iCount = 0\n",
        "    # Loop over all words of this question\n",
        "    for sWord in sQuestion.split():\n",
        "        # If word is embedded\n",
        "        if sWord in oWordEmbeddings:\n",
        "            # Add this embedding to question embedding\n",
        "            caResult += oWordEmbeddings[sWord]\n",
        "            # Number of embedded words inscrease\n",
        "            iCount += 1\n",
        "    # Return a mean of all word embedding in the question\n",
        "    return caResult / iCount if iCount != 0 else caResult"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtbGH_X-qXjL"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: LoadEmbeddings\n",
        "    \n",
        "    Objective: Load pre-trained word embeddings from tsv file\n",
        "    \n",
        "    Summary algorithmic description: Load pre-trained word embeddings from tsv file into a dict\n",
        "    \n",
        "    Input parameters: sEmbeddingsPath : path to the embeddings file\n",
        "    \n",
        "    Return : dict mapping words to vectors and dimension of the vectors\n",
        "    \n",
        "    Date : 06/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def LoadEmbeddings(sEmbeddingsPath):\n",
        "    # a mapping between keys and vectors \n",
        "    cdEmbedding = {}\n",
        "    # Open file embedding\n",
        "    with open(sEmbeddingsPath, encoding='utf-8') as f:  \n",
        "        # Read every line in file\n",
        "        for line in f.readlines():\n",
        "            # Separate key and vector\n",
        "            clLine = line.strip().split('\\t')\n",
        "            # Add key and vector embedding into the dictionnary\n",
        "            cdEmbedding[clLine[0]] = np.array(clLine[1:], dtype=np.float32)  \n",
        "    \n",
        "    # dimension of the vectors\n",
        "    iEmbeddingDim = cdEmbedding[list(cdEmbedding)[0]].shape[0]\n",
        "    # Return dict mapping words to vectors and dimension of the vectors\n",
        "    return cdEmbedding, iEmbeddingDim"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYCgUqng-26H"
      },
      "source": [
        "\"\"\"\n",
        "    Class name: ThreadRanker \n",
        "    \n",
        "    Objective: Find post id of the most similar thread for the question\n",
        "    \n",
        "    Summary algorithmic description: Load title embeddings of the tag\n",
        "                                     Find post id of the most similar thread for the question\n",
        "    \n",
        "    Input parameters: None\n",
        "    \n",
        "    Date : 06/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "class ThreadRanker(object):\n",
        "    def __init__(self):\n",
        "        # Load pre-trained starspace word embeddings from tsv file\n",
        "        self.cdWordEmbedding, self.iEmbeddingsDim = LoadEmbeddings(f'{DATA_FOLDER}/StarSpace_embeddings.tsv')\n",
        "        # thread embedding folder by tags\n",
        "        self.sThreadEmbeddingsFolder = f'{DATA_FOLDER}/thread_embeddings_by_tags'\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "        Function name: __load_embeddings_by_tag\n",
        "\n",
        "        Objective: Load title embeddings of the tag\n",
        "\n",
        "        Summary algorithmic description: Load thread embedding file by tag\n",
        "\n",
        "        Input parameters: sTagName : tag name\n",
        "\n",
        "        Return : post Ids of the tag and a matrix where embeddings for each title are stored\n",
        "    \"\"\"\n",
        "    def __load_embeddings_by_tag(self, sTagName):\n",
        "        # tag embedding file\n",
        "        sEmbeddingsPath = os.path.join(self.sThreadEmbeddingsFolder, sTagName + \".pkl\")\n",
        "        # Load tag embedding\n",
        "        caTagPostId, caTagVector = pickle.load(open(sEmbeddingsPath, 'rb'))\n",
        "        # Return post Ids of the tag and a matrix where embeddings for each title are stored.\n",
        "        return caTagPostId, caTagVector\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "        Function name: get_best_thread\n",
        "\n",
        "        Objective: Find post id of the most similar thread for the question\n",
        "\n",
        "        Summary algorithmic description: Calculate question embedding\n",
        "                                         Search the most similar thread for the question across the threads with a given tag\n",
        "\n",
        "        Input parameters: sQuestion : a question\n",
        "                          sTagName : tag name\n",
        "\n",
        "        Return : post id of the most similar thread for the question\n",
        "    \"\"\"\n",
        "    def get_best_thread(self, sQuestion, sTagName):\n",
        "        # Load title embeddings of the tag\n",
        "        caTagPostId, caTagVector = self.__load_embeddings_by_tag(sTagName)\n",
        "        # question embedding\n",
        "        caQuestionEmbedding = QuestionEmbedding(sQuestion, self.cdWordEmbedding, self.iEmbeddingsDim).reshape(1, -1)\n",
        "        # index of the post which is the most similar thread for the question\n",
        "        iBestThreadIndex = pairwise_distances_argmin(caQuestionEmbedding, caTagVector) \n",
        "        # Return id of the most similar thread for the question\n",
        "        return caTagPostId[iBestThreadIndex]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSCzd0T__I3m"
      },
      "source": [
        "\"\"\"\n",
        "    Class name: DialogueManager \n",
        "    \n",
        "    Objective: Train the chatbot model to generate a reponse\n",
        "    \n",
        "    Summary algorithmic description: Initialize and train chatbot model\n",
        "                                     Generate answer for Chit-chat part and programming-related question\n",
        "    \n",
        "    Input parameters: None\n",
        "    \n",
        "    Date : 06/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "class DialogueManager(object):\n",
        "    def __init__(self):\n",
        "        print(\"Loading resources...\")\n",
        "\n",
        "        # Intent recognition\n",
        "        self.oIntentRecognizer = pickle.load(open(f'{DATA_FOLDER}/intent_recognizer.pkl', 'rb')) \n",
        "        # TF-IDF vectorizer\n",
        "        self.oTFIDFVectorizer = pickle.load(open(f'{DATA_FOLDER}/tfidf_vectorizer.pkl', 'rb')) \n",
        "        # answer template\n",
        "        self.ANSWER_TEMPLATE = 'I think its about %s\\nThis thread might help you: https://stackoverflow.com/questions/%s'\n",
        "\n",
        "        # tag classifier\n",
        "        self.oTagClassifier = pickle.load(open(f'{DATA_FOLDER}/tag_classifier.pkl', 'rb')) \n",
        "        # Find post id of the most similar thread for the question\n",
        "        self.oThreadRanker = ThreadRanker()\n",
        "        # Initialize and train the chatbot model\n",
        "        self.__init_chitchat_bot()\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "        Function name: __init_chitchat_bot\n",
        "\n",
        "        Objective: Initialize and train chatbot model\n",
        "\n",
        "        Summary algorithmic description: Create an instance of the ChatBot class\n",
        "                                         Create a new trainer for the chatbot\n",
        "                                         Train the chatbot based on the english corpus\n",
        "\n",
        "        Input parameters: None\n",
        "\n",
        "        Return : None\n",
        "    \"\"\"\n",
        "    def __init_chitchat_bot(self):\n",
        "        # Create an instance of the ChatBot class\n",
        "        oChatbot = ChatBot('StackOverflow Assistance')\n",
        "        # Create a new trainer for the chatbot\n",
        "        oTrainer = ChatterBotCorpusTrainer(oChatbot)\n",
        "        # Train the chatbot based on the english corpus\n",
        "        oTrainer.train(\"chatterbot.corpus.english\")\n",
        "        # Chatbot model\n",
        "        self.oChitchatBot = oChatbot\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "        Function name: generate_answer\n",
        "\n",
        "        Objective: Generate answer for Chit-chat part and programming-related question\n",
        "\n",
        "        Summary algorithmic description: Recognize intent of the question using `intent_recognizer`\n",
        "                                         Pass question to chitchat_bot to generate a response\n",
        "                                         or to ThreadRanker to find post id of the most similar thread for the question\n",
        "\n",
        "        Input parameters: sQuestion : a question\n",
        "\n",
        "        Return : an answer\n",
        "    \"\"\"       \n",
        "    def generate_answer(self, sQuestion):\n",
        "        # Clean a raw question\n",
        "        sCleanedQuestion = CleanRawText(sQuestion) \n",
        "        # TF-IDF features of this question\n",
        "        caTFIDFFeature = self.oTFIDFVectorizer.transform([sCleanedQuestion]) \n",
        "        # Intent recognition; Labels will be either dialogue or stackoverflow for programming-related questions.\n",
        "        sIntent = self.oIntentRecognizer.predict(caTFIDFFeature) \n",
        "\n",
        "        # Chit-chat part: dialogue   \n",
        "        if sIntent == 'dialogue':\n",
        "            # Pass question to chitchat_bot to generate a response.       \n",
        "            sResponse = self.oChitchatBot.get_response(sQuestion)\n",
        "            # Return dialogue answer \n",
        "            return sResponse\n",
        "        \n",
        "        # Goal-oriented part: programming-related questions\n",
        "        else:        \n",
        "            # Pass features to tag_classifier to get predictions.\n",
        "            sTag = self.oTagClassifier.predict(caTFIDFFeature)[0] \n",
        "            \n",
        "            # Pass cleaned question to thread_ranker to get predictions.\n",
        "            iThreadId = self.oThreadRanker.get_best_thread(sQuestion, sTag)[0] \n",
        "            # Return answer of programming-related question\n",
        "            return self.ANSWER_TEMPLATE % (sTag, iThreadId)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiQYqOJS_LX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac592747-c3df-4136-8853-78b3095d8940"
      },
      "source": [
        "# Train the chatbot model to generate a reponse\n",
        "oDialogueManager = DialogueManager()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading resources...\n",
            "Training ai.yml: [####################] 100%\n",
            "Training botprofile.yml: [####################] 100%\n",
            "Training computers.yml: [####################] 100%\n",
            "Training conversations.yml: [####################] 100%\n",
            "Training emotion.yml: [####################] 100%\n",
            "Training food.yml: [####################] 100%\n",
            "Training gossip.yml: [####################] 100%\n",
            "Training greetings.yml: [####################] 100%\n",
            "Training health.yml: [####################] 100%\n",
            "Training history.yml: [####################] 100%\n",
            "Training humor.yml: [####################] 100%\n",
            "Training literature.yml: [####################] 100%\n",
            "Training money.yml: [####################] 100%\n",
            "Training movies.yml: [####################] 100%\n",
            "Training politics.yml: [####################] 100%\n",
            "Training psychology.yml: [####################] 100%\n",
            "Training science.yml: [####################] 100%\n",
            "Training sports.yml: [####################] 100%\n",
            "Training trivia.yml: [####################] 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu9v0rkDqUOR",
        "outputId": "d5d41329-30cd-4d91-ac26-d9591a298f97"
      },
      "source": [
        "# list of questions\n",
        "clQuestion = [\n",
        "    \"Hey\", \n",
        "    \"How are you doing?\", \n",
        "    \"What's your hobby?\", \n",
        "    \"How to write a loop in python?\",\n",
        "    \"How to delete rows in pandas?\",\n",
        "    \"python3 re\",\n",
        "    \"What is the difference between c and c++\",\n",
        "    \"Multithreading in Java\",\n",
        "    \"Catch exceptions C++\",\n",
        "    \"What is AI?\",\n",
        "]\n",
        "\n",
        "# Loop over all test questions\n",
        "for sQuestion in clQuestion:\n",
        "    # Generate answer for Chit-chat part and programming-related question\n",
        "    sAnswer = oDialogueManager.generate_answer(sQuestion) \n",
        "    print('Q: %s\\nA: %s \\n' % (sQuestion, sAnswer))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Hey\n",
            "A: Which is your favourite soccer club? \n",
            "\n",
            "Q: How are you doing?\n",
            "A: I am doing well. \n",
            "\n",
            "Q: What's your hobby?\n",
            "A: you act like a child \n",
            "\n",
            "Q: How to write a loop in python?\n",
            "A: I think its about python\n",
            "This thread might help you: https://stackoverflow.com/questions/26736277 \n",
            "\n",
            "Q: How to delete rows in pandas?\n",
            "A: I think its about python\n",
            "This thread might help you: https://stackoverflow.com/questions/24612584 \n",
            "\n",
            "Q: python3 re\n",
            "A: I think its about python\n",
            "This thread might help you: https://stackoverflow.com/questions/10769394 \n",
            "\n",
            "Q: What is the difference between c and c++\n",
            "A: I think its about c_cpp\n",
            "This thread might help you: https://stackoverflow.com/questions/25180069 \n",
            "\n",
            "Q: Multithreading in Java\n",
            "A: I think its about java\n",
            "This thread might help you: https://stackoverflow.com/questions/8318 \n",
            "\n",
            "Q: Catch exceptions C++\n",
            "A: I think its about c_cpp\n",
            "This thread might help you: https://stackoverflow.com/questions/336475 \n",
            "\n",
            "Q: What is AI?\n",
            "A: I think its about java\n",
            "This thread might help you: https://stackoverflow.com/questions/8318 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gDUR_ttqyrS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}