{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataProcess.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ixot-h-j2f8C",
        "outputId": "0722728a-46b4-4f0c-878e-2617aa91bef8"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1vt5xbN2lZ3"
      },
      "source": [
        "DATA_FOLDER = \"/content/drive/My Drive/StackOverflow Assistant Chatbot/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vslBR_e22rK2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrBbHMjY2vNl",
        "outputId": "cad67576-c96a-4c8f-d453-18bbc2dcfb8b"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO2CuBPk3C32"
      },
      "source": [
        "# sample size\n",
        "SAMPLE_SIZE = 200000\n",
        "\n",
        "# dialogue phrases from movie subtitles (negative samples)\n",
        "dfDialogue = pd.read_csv(f'{DATA_FOLDER}/dialogues.tsv', sep='\\t').sample(SAMPLE_SIZE, random_state=0)\n",
        "# StackOverflow posts, tagged with one programming language (positive samples)\n",
        "dfStackOverflow = pd.read_csv(f'{DATA_FOLDER}/tagged_posts.tsv', sep='\\t').sample(SAMPLE_SIZE, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "I6ApEJfr3KkU",
        "outputId": "064f12f2-8b71-4fd8-96f7-b31eb9a96af9"
      },
      "source": [
        "dfDialogue.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82925</th>\n",
              "      <td>Donna, you are a muffin.</td>\n",
              "      <td>dialogue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48774</th>\n",
              "      <td>He was here last night till about two o'clock....</td>\n",
              "      <td>dialogue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55394</th>\n",
              "      <td>All right, then make an appointment with her s...</td>\n",
              "      <td>dialogue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90806</th>\n",
              "      <td>Hey, what is this-an interview? We're supposed...</td>\n",
              "      <td>dialogue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107758</th>\n",
              "      <td>Yeah. He's just a friend of mine I was trying ...</td>\n",
              "      <td>dialogue</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text       tag\n",
              "82925                            Donna, you are a muffin.  dialogue\n",
              "48774   He was here last night till about two o'clock....  dialogue\n",
              "55394   All right, then make an appointment with her s...  dialogue\n",
              "90806   Hey, what is this-an interview? We're supposed...  dialogue\n",
              "107758  Yeah. He's just a friend of mine I was trying ...  dialogue"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5y-6FsJ03Msl",
        "outputId": "271a3136-896c-430c-ecaf-4cb99537ffdb"
      },
      "source": [
        "dfStackOverflow.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>title</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2168983</th>\n",
              "      <td>43837842</td>\n",
              "      <td>Efficient Algorithm to compose valid expressio...</td>\n",
              "      <td>python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1084095</th>\n",
              "      <td>15747223</td>\n",
              "      <td>Why does this basic thread program fail with C...</td>\n",
              "      <td>c_cpp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049020</th>\n",
              "      <td>15189594</td>\n",
              "      <td>Link to scroll to top not working</td>\n",
              "      <td>javascript</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200466</th>\n",
              "      <td>3273927</td>\n",
              "      <td>Is it possible to implement ping on windows ph...</td>\n",
              "      <td>c#</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1200249</th>\n",
              "      <td>17684551</td>\n",
              "      <td>GLSL normal mapping issue</td>\n",
              "      <td>c_cpp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          post_id  ...         tag\n",
              "2168983  43837842  ...      python\n",
              "1084095  15747223  ...       c_cpp\n",
              "1049020  15189594  ...  javascript\n",
              "200466    3273927  ...          c#\n",
              "1200249  17684551  ...       c_cpp\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAmLEqo83fIm"
      },
      "source": [
        "# Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcZitYYY3OIG"
      },
      "source": [
        "# special characters replaced by space\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "# Remove characters that are not 0-9, a-z, ' ', #, +, _\n",
        "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "# stop words\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCpoWFVK3kV1"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: CleanRawText\n",
        "    \n",
        "    Objective: Clean a raw text\n",
        "    \n",
        "    Summary algorithmic description: All characters in text are lower case\n",
        "                                     Remove characters that are not 0-9, a-z, ' ', #, +, _\n",
        "                                     Remove stop words\n",
        "    \n",
        "    Input parameters: sText : a text\n",
        "    \n",
        "    Return : the preprocessed text\n",
        "    \n",
        "    Date : 04/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def CleanRawText(sText):\n",
        "    # all characters in sText are lower case \n",
        "    sText = sText.lower()\n",
        "    # special characters replaced by space\n",
        "    sText = REPLACE_BY_SPACE_RE.sub(' ', sText)\n",
        "    # Remove characters that are not 0-9, a-z, ' ', #, +, _\n",
        "    sText = GOOD_SYMBOLS_RE.sub('', sText)\n",
        "    # Remove stop words\n",
        "    sText = ' '.join([sWord for sWord in sText.split() if sWord and sWord not in STOPWORDS])\n",
        "    # Return preprocessed text\n",
        "    return sText.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6ZboM2u3mS1"
      },
      "source": [
        "# Clean dialogue phrases\n",
        "dfDialogue['text'] = dfDialogue['text'].apply(CleanRawText) \n",
        "# Clean StackOverflow titles\n",
        "dfStackOverflow['title'] = dfStackOverflow['title'].apply(CleanRawText) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8DErnmT6fVv"
      },
      "source": [
        "# Save the cleaned data\n",
        "pickle.dump((dfDialogue, dfStackOverflow), open(f'{DATA_FOLDER}/cleaned_sample_data.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "678duuHg8XdW"
      },
      "source": [
        "# TF-IDF features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTmt08C28ufX"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: TfidfFeatures\n",
        "    \n",
        "    Objective: Perform TF-IDF transformation and dump the model\n",
        "    \n",
        "    Summary algorithmic description: \n",
        "\n",
        "    Input parameters: caTrainData : training data\n",
        "                      caTestData : test data\n",
        "                      sVectorizerPath : file path of TF-IDF features \n",
        "    \n",
        "    Return : trainning TF-IDF features and test TF-IDF features\n",
        "    \n",
        "    Date : 05/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def TfidfFeatures(caTrainData, caTestData, sVectorizerPath):\n",
        "    # a matrix of TF-IDF features : we filter out too rare words (occur less than in 5 titles) \n",
        "    # and too frequent words (occur more than in 90% of the titles)\n",
        "    # Also, use bigrams along with unigrams in your vocabulary.\n",
        "    oTfidfVectorizer = TfidfVectorizer(min_df=5, max_df=0.9, ngram_range=(1, 2), token_pattern='(\\S+)')\n",
        "    # Learn vocabulary and idf\n",
        "    caTrainFeature = oTfidfVectorizer.fit_transform(caTrainData)\n",
        "    # Transform documents to document-term matrix\n",
        "    caTestFeture = oTfidfVectorizer.transform(caTestData)\n",
        "    # Dump the model\n",
        "    with open(sVectorizerPath, 'wb') as f:\n",
        "        pickle.dump(oTfidfVectorizer, f)\n",
        "    # Return TF-IDF vectorized representation of train and test set\n",
        "    return caTrainFeature, caTestFeture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3P4kZru8W21",
        "outputId": "31670d0a-f8b1-4867-c2b3-62721ff23800"
      },
      "source": [
        "# concatenate dialogue and stackoverflow examples into one sample\n",
        "caData = np.concatenate([dfDialogue['text'].values, dfStackOverflow['title'].values])\n",
        "# concatenate dialogue and stackoverflow example tags into one sample\n",
        "clTrainTag = ['dialogue'] * dfDialogue.shape[0] + ['stackoverflow'] * dfStackOverflow.shape[0]\n",
        "# split it into train and test in proportion 9:1\n",
        "caTrainData, caTestData, clTrainTag, clTestTag = train_test_split(caData, clTrainTag, test_size=0.1, random_state=0) \n",
        "print('Train size = {}, test size = {}'.format(len(caTrainData), len(caTestData)))\n",
        "# transform it into TF-IDF features\n",
        "caTrainFeatureTFIDF, caTestFeatureTFIDF = TfidfFeatures(caTrainData, caTestData, f'{DATA_FOLDER}/tfidf_vectorizer.pkl') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size = 360000, test size = 40000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnonT5F08gff"
      },
      "source": [
        "# Save TF-IDF features and tags\n",
        "pickle.dump((caTrainFeatureTFIDF, caTestFeatureTFIDF, clTrainTag, clTestTag), open(f'{DATA_FOLDER}/tfidf_features.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUaD7OPk5Yi-"
      },
      "source": [
        "# Thread Embeddings by tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzT0cZy-6Bye"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: QuestionEmbedding\n",
        "    \n",
        "    Objective: Calculate question embedding\n",
        "    \n",
        "    Summary algorithmic description: a mean of all word embedding in the question\n",
        "    \n",
        "    Input parameters: sQuestion : question to embed\n",
        "                      oWordEmbeddings : dictionnary where the key is a word and a value is it's embedding\n",
        "                      iDim : size of the question embedding\n",
        "    \n",
        "    Return : question embedding\n",
        "    \n",
        "    Date : 28/11/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def QuestionEmbedding(sQuestion, oWordEmbeddings, iDim=300):\n",
        "    #  question embedding is initialized with filled zeros\n",
        "    caResult = np.zeros(iDim)\n",
        "    # Number of embedded words\n",
        "    iCount = 0\n",
        "    # Loop over all words of this question\n",
        "    for sWord in sQuestion.split():\n",
        "        # If word is embedded\n",
        "        if sWord in oWordEmbeddings:\n",
        "            # Add this embedding to question embedding\n",
        "            caResult += oWordEmbeddings[sWord]\n",
        "            # Number of embedded words inscrease\n",
        "            iCount += 1\n",
        "    # Return a mean of all word embedding in the question\n",
        "    return caResult / iCount if iCount != 0 else caResult"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDiQ1Zim5qMV"
      },
      "source": [
        "\"\"\"\n",
        "    Function name: LoadEmbeddings\n",
        "    \n",
        "    Objective: Load pre-trained word embeddings from tsv file\n",
        "    \n",
        "    Summary algorithmic description: Load pre-trained word embeddings from tsv file into a dict\n",
        "    \n",
        "    Input parameters: sEmbeddingsPath : path to the embeddings file\n",
        "    \n",
        "    Return : dict mapping words to vectors and dimension of the vectors\n",
        "    \n",
        "    Date : 06/12/2021\n",
        "    \n",
        "    Coding: INSA CVL - Van Tuan BUI  \n",
        "\"\"\"\n",
        "def LoadEmbeddings(sEmbeddingsPath):\n",
        "    # a mapping between keys and vectors \n",
        "    cdEmbedding = {}\n",
        "    # Open file embedding\n",
        "    with open(sEmbeddingsPath, encoding='utf-8') as f:  \n",
        "        # Read every line in file\n",
        "        for line in f.readlines():\n",
        "            # Separate key and vector\n",
        "            clLine = line.strip().split('\\t')\n",
        "            # Add key and vector embedding into the dictionnary\n",
        "            cdEmbedding[clLine[0]] = np.array(clLine[1:], dtype=np.float32)  \n",
        "    \n",
        "    # dimension of the vectors\n",
        "    iEmbeddingDim = cdEmbedding[list(cdEmbedding)[0]].shape[0]\n",
        "    # Return dict mapping words to vectors and dimension of the vectors\n",
        "    return cdEmbedding, iEmbeddingDim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmjkYo8J3ob1"
      },
      "source": [
        "# Load pre-trained starspace embeddings from tsv file\n",
        "cdStarspaceEmbedding, iEmbeddingDim = LoadEmbeddings(f'{DATA_FOLDER}/StarSpace_embeddings.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk5DwGJy5ngm"
      },
      "source": [
        "# Load full stackOverflow posts, tagged with one programming language (positive samples)\n",
        "dfStackOverflowPost = pd.read_csv(f'{DATA_FOLDER}/tagged_posts.tsv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG9rM7UG5083"
      },
      "source": [
        "# Group posts by tag\n",
        "dfCountByTag = dfStackOverflowPost.groupby(['tag'])['tag'].count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9OdoyJA580F"
      },
      "source": [
        "# Create the directory thread_embeddings_by_tags\n",
        "os.makedirs(f'{DATA_FOLDER}/thread_embeddings_by_tags', exist_ok=True)\n",
        "\n",
        "# Loop over all tags and it's count\n",
        "for sTag, iCount in dfCountByTag.items():\n",
        "    # StackOverflow posts with the same tag\n",
        "    dfStackOverflowTagPost = dfStackOverflowPost[dfStackOverflowPost['tag'] == sTag]\n",
        "    # Post Ids of the tag\n",
        "    caTagPostId = dfStackOverflowTagPost['post_id'].values \n",
        "    # a matrix where embeddings for each title are stored.\n",
        "    caTagVector = np.zeros((iCount, iEmbeddingDim), dtype=np.float32)\n",
        "    # Loop over all titles of all posts of the tag\n",
        "    for iIndex, sTitle in enumerate(dfStackOverflowTagPost['title']):\n",
        "        # Calculate title embedding\n",
        "        caTagVector[iIndex, :] = QuestionEmbedding(sTitle, cdStarspaceEmbedding, iEmbeddingDim) \n",
        "\n",
        "    # Dump post ids and vectors to a file.\n",
        "    sFilename = os.path.join(f'{DATA_FOLDER}/thread_embeddings_by_tags', os.path.normpath('%s.pkl' % sTag))\n",
        "    pickle.dump((caTagPostId, caTagVector), open(sFilename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}